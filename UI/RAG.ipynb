{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a16358-8a3d-4ae8-82cf-2b2a0fdfd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from flask import Flask,redirect,url_for,render_template,request,jsonify\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_openai import AzureOpenAIEmbeddings, OpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "os.environ[\"AZURE_AI_SEARCH_SERVICE_NAME\"] = \"https://ragservice123.search.windows.net\"\n",
    "os.environ[\"AZURE_AI_SEARCH_INDEX_NAME\"] = \"major-business-incident\"\n",
    "os.environ[\"AZURE_AI_SEARCH_API_KEY\"] = \"kYTk8LtHQDvTb2LnYqG09vbeBNSwEB1287MrZbqkgFAzSeCNW3gO\"\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://gh018-m3fob2dq-swedencentral.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"5JYysB7CedH4g26m0WwUhPqDgkcvDKu6PWVmMTwHfKpvhwZ6pbizJQQJ99AKACfhMk5XJ3w3AAAAACOGjeKe\"\n",
    "\n",
    "\n",
    "retriever = AzureAISearchRetriever(\n",
    "    content_key=\"content\", top_k=1, index_name=\"major-business-incident\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-4o\",  # or your deployment\n",
    "    api_version=\"2024-08-01-preview\",  # or your api version\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "\n",
    "message = \"\"\"\n",
    "<Instructions>\n",
    "\n",
    "You are a powerful AI-Assistant and you will be given with historical ticket description and corresponding resolution as context , your task is to use this context to generate resolution for current ticket being raised by the user. The details of current ticket description will be provided to you as well.\n",
    "\n",
    "<context>\n",
    "\n",
    "{context}\n",
    "\n",
    "</context>\n",
    "\n",
    "Generate resolution for current ticket description using the context provided above, also make sure to follow the rules mentioned below\n",
    "\n",
    "<rules>\n",
    "\n",
    "1.The ticket resolution provided for current ticket should be in the same format as historical ticket resolution provided in the context\n",
    "2.The ticket resolution provided for current ticket should only be generated using context provided, if required information is not in the context provided then generate response as I do not have required information to provide resolution for this ticket.\n",
    "\n",
    "</rules>\n",
    "\n",
    "Current Ticket Description:\n",
    "\n",
    "{question}\n",
    "\n",
    "</Instructions>\n",
    "\n",
    "Assistant:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])\n",
    "\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Serve the main HTML page\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template(\"UI v3.html\")\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/run-script', methods=['POST'])\n",
    "def llm_call():\n",
    "    question =  request.json.get('content', '')\n",
    "    response = rag_chain.invoke(question)\n",
    "    llm_result = response.content\n",
    "    return llm_result\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack",
   "language": "python",
   "name": "hack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
